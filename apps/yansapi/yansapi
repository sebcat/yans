#!/usr/bin/env yans
-- vim: set syntax=lua :
local JAPI        = require "japi"
local Store       = require "svcs.store"
local Kneg        = require "svcs.kneg"

local DAEMON_NAME = "yansapi"
local SCANTYPE    = "scanny"

local function atoi(s, def)
  return math.floor(tonumber(s) or def)
end

local function clamp(val, min, max)
  return math.max(math.min(val, max), min)
end

local function clean_id(str)
  if type(str) == "string" then
    local id = str:match("[0-9a-f]+")
    if id:len() == 20 then
      return id
    end
  end
end

local function get_manifest(ctx)
  --[[
  GET /a1/manifest

  Response object on success:
  {
    "success": true,
    "data": {
      "entries": [
        "entry0",
        "entry1",
        ...
        "entryN"
      ]
    }
  }
  ]]--

  local manifest = ctx.data.kneg:manifest()
  local entries = json.from_str"[]"
  for e in string.gmatch(manifest, "[^ \r\n\t]+") do
    entries = entries << e
  end
  local data = json.from_str"{}"
  data.entries = entries
  local resp = json.from_str"{}"
  resp.success = true
  resp.data = data

  -- send the response
  ctx:status"200 OK"
  ctx:write(tostring(resp))
end

local function get_reports(ctx)
  --[[
  GET /a1/reports

  URL Parameters:
    - nelems (opt): Number of elements to fetch. Range: 0 <= nelems <= 100.
                    default: 25
    - before (opt): Fetch indices before a given row.

  Response object on success:
  {
    "success": true,
    "data": {
      "now_ts": 666,
      "entries": [
        {
          "row": 0,
          "ts": 1530356368,
          "id": "70a7a85d0004f8b9c2be",
          "status": "str"
        },
        ...
      ]
    }
  }
  ]]--

  -- parse the request parameters, provide sane defaults and limits
  local params = ctx:parse_query_string(ctx.query_string)
  local nelems = clamp(atoi(params.nelems, 25), 0, 100)
  local before = math.max(atoi(params.before, 0), 0)

  -- get the rows from the store index
  local rows = {}
  local ids  = {}
  for _, e in ipairs(ctx.data.store:index():get(nelems, before)) do
    table.insert(ids, e.id)
    table.insert(rows, e)
  end

  -- check with kneg status
  if #ids > 0 then
    local statuses = ctx.data.kneg:status(ids)
    local i = 1
    for status in string.gmatch(statuses, "[^ \r\n\t]+") do
      rows[i].status = status
      i = i + 1
    end
  end

  -- serialize the response 
  local resp = json.from_str"{}"
  local entries = json.from_str"[]"
  for _, e in ipairs(rows) do
    local entry = json.from_str"{}"
    entry.id, entry.name, entry.ts, entry.row, entry.status =
        e.id, e.name, e.ts, e.row, e.status
    entries = entries << entry
  end
  local data = json.from_str"{}"
  data.entries = entries
  data.now_ts = os.time()
  resp.success = true
  resp.data = data

  -- send the response
  ctx:status"200 OK"
  ctx:write(tostring(resp))
end

local function err400(ctx, text)
    ctx:status"400 Bad Request"
    ctx:header("Content-Type", "text/plain")
    ctx:write(text)
end

local function get_report_section(ctx)
  --[[
  GET /a1/report-section

  URL Parameters:
    - id:    ID of the given report.
    - name: Name of section

  If id or entry is missing or invalid, a 400 response is returned.

  Response on success: The report section. Who knows what it contains, muahaha
  ]]--

  -- parse request
  local params = ctx:parse_query_string(ctx.query_string)
  local id     = clean_id(params.id)
  local name   = params.name

  -- validate parameters
  if not id or not name then
    err400(ctx, "Missing parameter 'id' and/or 'name'")
    return
  end

  -- open the store entry, or error out
  local store = ctx.data.store
  store:enter{id=id}
  local ok, res = pcall(store.open, store, name, yans.file.O_RDONLY)
  if not ok then
    err400(ctx, "Unable to open the requested report section")
    return
  end

  -- check if the client accepts gzip as a content encoding
  -- XXX: doesn't take qvalues into account, e.g., q=0
  local accept = ctx.hdrmap["HTTP_ACCEPT_ENCODING"]
  local client_accepts_gzip = accept and accept:match("gzip")
  local content_is_gzip = false
  if name:match(".gz$") then
    content_is_gzip = true
    -- trim the name to remove .gz, for later content-type identification
    name = name:sub(1, -4)
  end

  -- open the stream, decode it if it's compressed and the client does not
  -- support compression
  local stream
  if content_is_gzip and not client_accepts_gzip then
    stream = res:to_stream("zlib:rb")
  else
    stream = res:to_stream("rb")
  end

  -- set Content-Encoding, if neeed
  if content_is_gzip and client_accepts_gzip then
    ctx:header("Content-Encoding", "gzip")
  end

  -- Set Content-Type. any .gz suffix is trimmed earlier
  if name:match(".json$") then
    ctx:header("Content-Type", "application/json")
  elseif name:match(".csv$") then
    ctx:header("Content-Type", "application/vnd.ms-excel")
  elseif name:match(".txt$") then
    ctx:header("Content-Type", "text/plain")
  elseif name:match(".log$") then
    ctx:header("Content-Type", "text/plain")
  else
    ctx:header("Content-Type", "application/octet-stream")
  end

  -- send all the datas! read it into memory in chunks if the
  -- file is big-ish
  ctx:status"200 OK"
  while true do
    local data = stream:read(524288)
    if not data then break end
    ctx:write(data)
  end
end

local function get_report_sections(ctx)
  --[[
  GET /a1/report-sections

  URL Parameters:
    - id (opt): ID of the given report. If omitted, returns empty 'data'.

  Response object on success:
  {
    "success": true,
    "data": {
      "id": "str",
      "name": "str",
      "subject": "str",
      "indexed": 666,
      "now_ts": 777,
      "status": "str",
      "entries": [
        {
          "name": "str",
          "nbytes": 0
        },
        ...
      ]
    }
  }
  ]]--
  local store  = ctx.data.store
  local kneg   = ctx.data.kneg

  -- parse request
  local params = ctx:parse_query_string(ctx.query_string)
  local id     = clean_id(params.id)

  -- Listed entries must conform to this regex. Everything in the store can
  -- still be fetched by name, but only the entries matched by this regex are
  -- listed.
  local must_match = "^report-[0-9]+-[^.]+.(csv|txt)(.gz)?$"

  -- build response
  local datastr
  local status = "n/a"
  local entries = json.from_str"[]"
  if id then
    status = ctx.data.kneg:status(id)
    local etable = store:list(id, must_match)
    for i = 1, #etable, 2 do
      local entry = json.from_str"{}"
      entry.name   = etable[i]
      entry.nbytes = atoi(etable[i + 1], -1)
      entries = entries << entry
    end

    -- enter store and fetch job data. If the job data is missing, due
    -- to the job being started manually, we should not fail and the
    -- UI should be able to handle the missing time &c
    store:enter{id=id}
    local ok, ret = pcall(store.open, store, "job.json",
        yans.file.O_RDONLY)
    if ok then
      datastr = ret:to_stream("rb"):read("a")
    end
    if not datastr or #datastr < 2 then
      datastr = "{}"
    end
  end
  local data   = json.from_str(datastr)
  data.id      = id
  data.now_ts  = os.time()
  data.status  = status
  data.entries = entries
  local res    = json.from_str"{}"
  res.success  = true
  res.data     = data

  -- send response
  ctx:status"200 OK"
  ctx:write(tostring(res))
end

local function post_scan(ctx)
  --[[
  POST /a1/scan

  Request object:
  {
    "..."
  }

  Response object on success:
  {
    "success": true,
    "data": {

    }
  }
  ]]--

  local req = ctx.req_body
  if not req then
    err400(ctx, "missing request body")
    return
  end

  local subject = string.lower(req.subject or "")
  if #subject == 0 then
    err400(ctx, "missing scan subject")
    return
  end

  if string.match(subject, "%s") then
    err400(ctx, "scan subject contains whitespace")
    return
  end

  -- must contain at least a dot (IPv4 addrs, FQDN) or : (IPv6 addrs)
  if not string.match(subject, "[.:]") then
    err400(ctx, "invalid scan subject")
    return
  end

  -- set the name of the store to an appropriate length of the subject
  -- string
  local store_name = string.sub(subject, 1, 40)
  if #store_name < #subject then
    store_name = store_name .. "..."
  end

  -- create new store and write the request to it
  local store, kneg, file = ctx.data.store, ctx.data.kneg, yans.file
  local started = os.time()
  local id = store:enter()
  req.name = store_name
  req.started = started
  store:open("job.json", file.O_WRONLY | file.O_CREAT |
      file.O_TRUNC):to_stream("wb"):write(tostring(req)):close()

  -- Start kneg scan with same ID
  kneg:queue{
    type = SCANTYPE,
    id   = id,
    name = store_name,
  }

  -- build response
  local data  = json.from_str"{}"
  data.id     = id
  local res   = json.from_str"{}"
  res.success = true
  res.data    = data
  
  -- write response
  ctx:status("200 OK")
  ctx:write(tostring(res))
end

local function get_fail(ctx)
  error("get fail called")
end

local function handle_fail(fn)
  --[[
  pcall's fn, logs and responds with the proper JSON on failure

  Response object:
  {
    "success": false,
    "errmsg": "str"
  }
  ]]--
  return function(ctx)
    local ok, err = pcall(fn, ctx)
    if not ok then
      yans.ylog.error("request failure: %s", err)
      ctx:status"200 OK" -- all well that ends well, is it not?
      ctx:write'{"success":false,"errmsg":"An internal error occurred, sorry for the inconvenience"}'
    end
  end
end

JAPI:routes{
  ["GET /a1/manifest"]         = handle_fail(get_manifest),
  ["GET /a1/reports"]          = handle_fail(get_reports),
  ["GET /a1/report-sections"]  = handle_fail(get_report_sections),
  ["GET /a1/report-section"]   = handle_fail(get_report_section),
  ["POST /a1/scan"]            = handle_fail(post_scan),
  ["GET /a1/fail"]             = handle_fail(get_fail),
}

-- returns a table that will end up in ctx.data in the handlers. Used to
-- setup pre-sandbox stuff
local function prehook()
  local msgbuf = yans.ycl.msgbuf()
  -- FIXME: Store path varies depending on chroot/no chroot
  local store = Store:new{path = "stored/stored.sock", msgbuf = msgbuf}
  local kneg = Kneg:new{path = "knegd/knegd.sock", msgbuf = msgbuf}
  return {store = store, kneg = kneg}
end

-- parse command line options as parameters
local p = yans.opts:new()
p:str("user", "u", "daemon user")
p:str("group", "g", "daemon group")
p:str("basepath", "b", "daemon basepath")
p:flag("no-daemon", "n", "do not daemonize")
p:flag("help", "h", "this text")
local params = p:parse(args)
if params.help then
  io.stdout:write(p:usage())
  os.exit(1)
end

-- set default parameter values
params.user = params.user or "yansapi"
params.group = params.group or "yans"
params.basepath = params.basepath or "/var/yans"

-- since the daemon chroots, the paths will be different
local serve_path
if params["no-daemon"] then
  serve_path = params.basepath.."/"..DAEMON_NAME..".sock"
else
  serve_path = DAEMON_NAME..".sock"
end

-- create the sc2 server
local server = {
  path = serve_path,
  servefunc = function()
    JAPI:dispatch(prehook())
  end,
  donefunc = function(pid, duration, cause, code)
    local fmt = "served request pid:%d duration:%fs %s %d"
    local msg = string.format(fmt, pid, duration, cause, code)
    if cause == "exit" and code == 0 then
      yans.ylog.info(msg)
    else
      yans.ylog.error(msg)
    end
  end,
  errfunc = function(err)
    yans.ylog.error("serve error: %s", tostring(err))
  end,
}

-- Always log to syslog, since we don't want any logs in the children to end
-- up in the HTTP responses
yans.ylog.init(DAEMON_NAME, yans.ylog.SYSLOG)

if not params["no-daemon"] then
  yans.util.daemonize(DAEMON_NAME, params.basepath, params.user, params.group)
end

-- OK, let's do this!
yans.ylog.info("Starting "..DAEMON_NAME)
local serve_ok, serve_err = pcall(yans.sc2.serve, server)

-- Remove the PID-file if we're in daemon mode
if not params["no-daemon"] then
  yans.util.daemon_remove_pidfile(DAEMON_NAME, params.basepath)
end

-- Error out if sc2.serve failed
if not serve_ok then
  error(serve_err)
end
